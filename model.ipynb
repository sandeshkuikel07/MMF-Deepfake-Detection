{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9757503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3faba313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"A simple MLP for binary classification.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim1=512, hidden_dim2=256, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim2, 1) # Output is a single logit\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1bd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset to load pre-extracted features.\n",
    "    This version reads from metadata to be more robust.\n",
    "    \"\"\"\n",
    "    def __init__(self, domains, split='train'):\n",
    "        self.domains = domains\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "\n",
    "        metadata_path = 'ffpp_metadata.csv'\n",
    "        if not os.path.exists(metadata_path):\n",
    "            raise FileNotFoundError(f\"Metadata file not found at {metadata_path}. Please run download_and_prepare_ffpp.py first.\")\n",
    "        \n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        \n",
    "        # Simple split for demonstration. For a real project, use a more robust split.\n",
    "        train_df = metadata.sample(frac=0.8, random_state=42)\n",
    "        val_df = metadata.drop(train_df.index)\n",
    "        \n",
    "        df = train_df if split == 'train' else val_df\n",
    "\n",
    "        print(f\"Loading {split} dataset with {len(df)} videos...\")\n",
    "\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Loading {split} features\"):\n",
    "            label = row['label']\n",
    "            video_id = row['video_id']\n",
    "            \n",
    "            # Directory where preprocessed faces for this video are stored\n",
    "            faces_dir = os.path.join('preprocessed_faces', label, video_id)\n",
    "            if not os.path.exists(faces_dir):\n",
    "                continue\n",
    "            \n",
    "            # Find all the frame images that were preprocessed\n",
    "            for image_file in os.listdir(faces_dir):\n",
    "                if image_file.endswith('.png'):\n",
    "                    # Check if the corresponding feature file exists for all requested domains\n",
    "                    feature_paths_exist = True\n",
    "                    feature_paths_for_frame = {}\n",
    "\n",
    "                    for domain in self.domains:\n",
    "                        feature_filename = image_file.replace('.png', '.npy')\n",
    "                        # Prefer nested path: extracted_features/<domain>/<label>/<video_id>/<frame>.npy\n",
    "                        nested_feature_path = os.path.join('extracted_features', domain, label, video_id, feature_filename)\n",
    "                        # Fallback to flat path if project was extracted that way\n",
    "                        flat_feature_path = os.path.join('extracted_features', domain, label, feature_filename)\n",
    "                        feature_path = nested_feature_path if os.path.exists(nested_feature_path) else flat_feature_path\n",
    "                        \n",
    "                        if not os.path.exists(feature_path):\n",
    "                            feature_paths_exist = False\n",
    "                            break\n",
    "                        feature_paths_for_frame[domain] = feature_path\n",
    "                    \n",
    "                    if feature_paths_exist:\n",
    "                        self.features.append(feature_paths_for_frame)\n",
    "                        self.labels.append(1 if label == 'fake' else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_paths = self.features[idx]\n",
    "        \n",
    "        # Load and concatenate features from all specified domains\n",
    "        loaded_features = [np.load(feature_paths[domain]) for domain in self.domains]\n",
    "        combined_features = np.concatenate(loaded_features).astype(np.float32)\n",
    "        \n",
    "        label = np.float32(self.labels[idx])\n",
    "        \n",
    "        return torch.from_numpy(combined_features), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f815795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters directly (no argparse)\n",
    "default_epochs = 10\n",
    "default_batch_size = 128\n",
    "default_lr = 1e-4\n",
    "\n",
    "# Model configurations for different domains\n",
    "configs = {\n",
    "    'Spatial': {\n",
    "        'domains': ['spatial'],\n",
    "        'epochs': 15,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 2e-4,\n",
    "        'hidden_dim1': 1024,\n",
    "        'hidden_dim2': 512,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'Frequency': {\n",
    "        'domains': ['frequency'],\n",
    "        'epochs': 20,\n",
    "        'batch_size': 256,\n",
    "        'learning_rate': 5e-4,\n",
    "        'hidden_dim1': 128,\n",
    "        'hidden_dim2': 64,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'Semantic': {\n",
    "        'domains': ['semantic'],\n",
    "        'epochs': 12,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-4,\n",
    "        'hidden_dim1': 512,\n",
    "        'hidden_dim2': 256,\n",
    "        'dropout': 0.4\n",
    "    },\n",
    "    'Fused (All)': {\n",
    "        'domains': ['spatial', 'frequency', 'semantic'],\n",
    "        'epochs': 10,\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 1e-4,\n",
    "        'hidden_dim1': 512,\n",
    "        'hidden_dim2': 256,\n",
    "        'dropout': 0.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421bdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(domains, epochs, batch_size, learning_rate, hidden_dim1=512, hidden_dim2=256, dropout=0.5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model for a given set of feature domains.\n",
    "    Optimized for GPU (RTX 3060) with automatic fallback to CPU.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Pipeline for Domain(s): {', '.join(domains)} ---\")\n",
    "    print(f\"Hyperparameters: epochs={epochs}, batch_size={batch_size}, lr={learning_rate}\")\n",
    "    print(f\"Model architecture: hidden_dims=({hidden_dim1}, {hidden_dim2}), dropout={dropout}\")\n",
    "\n",
    "    # GPU setup and status - Force NVIDIA GPU (not AMD integrated graphics)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    if use_cuda:\n",
    "        # Explicitly set NVIDIA GPU (GPU 1 in your system)\n",
    "        torch.cuda.set_device(0)  # CUDA device 0 = NVIDIA RTX 3060\n",
    "        device = torch.device('cuda:0')\n",
    "        \n",
    "        print(f\"✓ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  - GPU Index: cuda:0 (NVIDIA RTX 3060 Laptop GPU)\")\n",
    "        print(f\"  - CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"  - GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Current GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "        \n",
    "        # Enable cuDNN autotuner for better performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"⚠ GPU not available, using CPU\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = FeatureDataset(domains=domains, split='train')\n",
    "    val_dataset = FeatureDataset(domains=domains, split='val')\n",
    "\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"\\nERROR: Dataset is empty.\")\n",
    "        print(\"Please ensure feature extraction was successful and that the 'extracted_features' directory is not empty.\")\n",
    "        return None\n",
    "\n",
    "    # DataLoader settings optimized for GPU\n",
    "    is_windows = platform.system() == 'Windows'\n",
    "    num_workers = 0 if is_windows else 4\n",
    "    pin_memory = use_cuda  # Enable for faster CPU->GPU transfer\n",
    "    persistent_workers = num_workers > 0\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers\n",
    "    )\n",
    "\n",
    "    # Define model, loss, optimizer\n",
    "    input_dim = train_dataset[0][0].shape[0]\n",
    "    model = MLP(input_dim=input_dim, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, dropout=dropout)\n",
    "    model.to(device)\n",
    "    \n",
    "    if use_cuda:\n",
    "        print(f\"✓ Model loaded on GPU with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n",
    "            features, labels = features.to(device), labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\"):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten() >= 0.5\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    print(f\"Validation Metrics: Acc: {accuracy:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return {'Domain': ' + '.join(domains), 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ba3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Pipeline for Domain(s): spatial ---\n",
      "Hyperparameters: epochs=15, batch_size=64, lr=0.0002\n",
      "Model architecture: hidden_dims=(1024, 512), dropout=0.3\n",
      "✓ Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "  - GPU Index: cuda:0 (NVIDIA RTX 3060 Laptop GPU)\n",
      "  - CUDA Version: 12.1\n",
      "  - GPU Memory: 6.00 GB\n",
      "  - Current GPU Memory Allocated: 16.25 MB\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 718.40it/s]\n",
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 718.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 764.35it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on GPU with 2623489 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 38.45it/s]\n",
      "Epoch 1/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 38.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.35it/s]\n",
      "Epoch 2/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 43.38it/s]\n",
      "Epoch 3/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 45.63it/s]\n",
      "Epoch 4/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 45.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.3434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 57.12it/s]\n",
      "Epoch 5/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.89it/s]\n",
      "Epoch 6/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.3153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.12it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.37it/s]\n",
      "Epoch 8/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 57.50it/s]\n",
      "Epoch 9/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 57.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.16it/s]\n",
      "Epoch 10/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 58.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 57.46it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 56.14it/s]\n",
      "Epoch 12/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.2177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 44.67it/s]\n",
      "Epoch 13/15 [Training]: 100%|██████████| 88/88 [00:01<00:00, 44.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.98it/s]\n",
      "Epoch 14/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.74it/s]\n",
      "Epoch 15/15 [Training]: 100%|██████████| 88/88 [00:02<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 [Validation]: 100%|██████████| 22/22 [00:00<00:00, 60.56it/s]\n",
      "Epoch 15/15 [Validation]: 100%|██████████| 22/22 [00:00<00:00, 60.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: Acc: 0.7548, Prec: 0.8696, Rec: 0.8507, F1: 0.8601\n",
      "\n",
      "--- Running Pipeline for Domain(s): frequency ---\n",
      "Hyperparameters: epochs=20, batch_size=256, lr=0.0005\n",
      "Model architecture: hidden_dims=(128, 64), dropout=0.1\n",
      "✓ Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "  - GPU Index: cuda:0 (NVIDIA RTX 3060 Laptop GPU)\n",
      "  - CUDA Version: 12.1\n",
      "  - GPU Memory: 6.00 GB\n",
      "  - Current GPU Memory Allocated: 16.25 MB\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 664.78it/s]\n",
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 664.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 722.18it/s]\n",
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 722.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on GPU with 8961 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.85it/s]\n",
      "Epoch 1/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.15it/s]\n",
      "Epoch 2/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.27it/s]\n",
      "Epoch 3/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.03it/s]\n",
      "Epoch 4/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.4216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.05it/s]\n",
      "Epoch 5/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.4196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.02it/s]\n",
      "Epoch 6/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.4213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.10it/s]\n",
      "Epoch 7/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.17it/s]\n",
      "Epoch 8/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.35it/s]\n",
      "Epoch 9/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.98it/s]\n",
      "Epoch 10/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.4182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.39it/s]\n",
      "Epoch 11/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.4168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 17.47it/s]\n",
      "Epoch 12/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.43it/s]\n",
      "Epoch 13/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 0.4150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.44it/s]\n",
      "Epoch 14/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 0.4161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.96it/s]\n",
      "Epoch 15/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 0.4147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.24it/s]\n",
      "Epoch 16/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Training Loss: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.37it/s]\n",
      "Epoch 17/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Training Loss: 0.4157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.34it/s]\n",
      "Epoch 18/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Training Loss: 0.4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.90it/s]\n",
      "Epoch 19/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Training Loss: 0.4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.67it/s]\n",
      "Epoch 20/20 [Training]: 100%|██████████| 22/22 [00:01<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Training Loss: 0.4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Validation]: 100%|██████████| 6/6 [00:00<00:00, 21.88it/s]\n",
      "Epoch 20/20 [Validation]: 100%|██████████| 6/6 [00:00<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: Acc: 0.8856, Prec: 0.8856, Rec: 1.0000, F1: 0.9393\n",
      "\n",
      "--- Running Pipeline for Domain(s): semantic ---\n",
      "Hyperparameters: epochs=12, batch_size=32, lr=0.0001\n",
      "Model architecture: hidden_dims=(512, 256), dropout=0.4\n",
      "✓ Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "  - GPU Index: cuda:0 (NVIDIA RTX 3060 Laptop GPU)\n",
      "  - CUDA Version: 12.1\n",
      "  - GPU Memory: 6.00 GB\n",
      "  - Current GPU Memory Allocated: 16.25 MB\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 696.45it/s]\n",
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 696.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 729.86it/s]\n",
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 729.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on GPU with 525313 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 84.34it/s]\n",
      "Epoch 1/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 84.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 85.56it/s]\n",
      "Epoch 2/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 85.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 85.94it/s]\n",
      "Epoch 3/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 85.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.90it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 84.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 82.43it/s]\n",
      "Epoch 6/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 82.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.99it/s]\n",
      "Epoch 7/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 80.14it/s]\n",
      "Epoch 8/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 80.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.11it/s]\n",
      "Epoch 9/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.2513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 82.86it/s]\n",
      "Epoch 10/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 82.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 80.24it/s]\n",
      "Epoch 11/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 80.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.02it/s]\n",
      "Epoch 12/12 [Training]: 100%|██████████| 175/175 [00:02<00:00, 83.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/12 [Validation]: 100%|██████████| 44/44 [00:00<00:00, 126.71it/s]\n",
      "Epoch 12/12 [Validation]: 100%|██████████| 44/44 [00:00<00:00, 126.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: Acc: 0.7748, Prec: 0.8720, Rec: 0.8741, F1: 0.8730\n",
      "\n",
      "--- Running Pipeline for Domain(s): spatial, frequency, semantic ---\n",
      "Hyperparameters: epochs=10, batch_size=128, lr=0.0001\n",
      "Model architecture: hidden_dims=(512, 256), dropout=0.5\n",
      "✓ Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "  - GPU Index: cuda:0 (NVIDIA RTX 3060 Laptop GPU)\n",
      "  - CUDA Version: 12.1\n",
      "  - GPU Memory: 6.00 GB\n",
      "  - Current GPU Memory Allocated: 16.25 MB\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:01<00:00, 240.87it/s]\n",
      "Loading train features: 100%|██████████| 280/280 [00:01<00:00, 240.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 250.27it/s]\n",
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 250.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on GPU with 1575937 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]: 100%|██████████| 44/44 [00:04<00:00,  9.79it/s]\n",
      "Epoch 1/10 [Training]: 100%|██████████| 44/44 [00:04<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.68it/s]\n",
      "Epoch 2/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.93it/s]\n",
      "Epoch 3/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.36it/s]\n",
      "Epoch 4/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.27it/s]\n",
      "Epoch 5/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.3575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.20it/s]\n",
      "Epoch 6/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.21it/s]\n",
      "Epoch 7/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.98it/s]\n",
      "Epoch 8/10 [Training]: 100%|██████████| 44/44 [00:04<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.51it/s]\n",
      "Epoch 9/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.3055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.47it/s]\n",
      "Epoch 10/10 [Training]: 100%|██████████| 44/44 [00:03<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Validation]: 100%|██████████| 11/11 [00:00<00:00, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: Acc: 0.8670, Prec: 0.8835, Rec: 0.9790, F1: 0.9288\n",
      "\n",
      "\n",
      "--- Final Performance Comparison ---\n",
      "                        Domain  Accuracy  Precision   Recall       F1\n",
      "                       spatial  0.754825   0.869637 0.850686 0.860057\n",
      "                     frequency  0.885633   0.885633 1.000000 0.939348\n",
      "                      semantic  0.774839   0.871981 0.874092 0.873035\n",
      "spatial + frequency + semantic  0.867048   0.883467 0.979015 0.928790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, config in configs.items():\n",
    "    result = run_pipeline(\n",
    "        domains=config['domains'],\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        hidden_dim1=config['hidden_dim1'],\n",
    "        hidden_dim2=config['hidden_dim2'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# --- Print Final Comparison Table ---\n",
    "if results:\n",
    "    print(\"\\n\\n--- Final Performance Comparison ---\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc5782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79523f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
