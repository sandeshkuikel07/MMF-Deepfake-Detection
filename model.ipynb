{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9757503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3faba313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"A simple MLP for binary classification.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim1=512, hidden_dim2=256, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim2, 1) # Output is a single logit\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1bd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset to load pre-extracted features.\n",
    "    This version reads from metadata to be more robust.\n",
    "    \"\"\"\n",
    "    def __init__(self, domains, split='train'):\n",
    "        self.domains = domains\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "\n",
    "        metadata_path = 'ffpp_metadata.csv'\n",
    "        if not os.path.exists(metadata_path):\n",
    "            raise FileNotFoundError(f\"Metadata file not found at {metadata_path}. Please run download_and_prepare_ffpp.py first.\")\n",
    "        \n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        \n",
    "        # Simple split for demonstration. For a real project, use a more robust split.\n",
    "        train_df = metadata.sample(frac=0.8, random_state=42)\n",
    "        val_df = metadata.drop(train_df.index)\n",
    "        \n",
    "        df = train_df if split == 'train' else val_df\n",
    "\n",
    "        print(f\"Loading {split} dataset with {len(df)} videos...\")\n",
    "\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Loading {split} features\"):\n",
    "            label = row['label']\n",
    "            video_id = row['video_id']\n",
    "            \n",
    "            # Directory where preprocessed faces for this video are stored\n",
    "            faces_dir = os.path.join('preprocessed_faces', label, video_id)\n",
    "            if not os.path.exists(faces_dir):\n",
    "                continue\n",
    "            \n",
    "            # Find all the frame images that were preprocessed\n",
    "            for image_file in os.listdir(faces_dir):\n",
    "                if image_file.endswith('.png'):\n",
    "                    # Check if the corresponding feature file exists for all requested domains\n",
    "                    feature_paths_exist = True\n",
    "                    feature_paths_for_frame = {}\n",
    "\n",
    "                    for domain in self.domains:\n",
    "                        feature_filename = image_file.replace('.png', '.npy')\n",
    "                        # Prefer nested path: extracted_features/<domain>/<label>/<video_id>/<frame>.npy\n",
    "                        nested_feature_path = os.path.join('extracted_features', domain, label, video_id, feature_filename)\n",
    "                        # Fallback to flat path if project was extracted that way\n",
    "                        flat_feature_path = os.path.join('extracted_features', domain, label, feature_filename)\n",
    "                        feature_path = nested_feature_path if os.path.exists(nested_feature_path) else flat_feature_path\n",
    "                        \n",
    "                        if not os.path.exists(feature_path):\n",
    "                            feature_paths_exist = False\n",
    "                            break\n",
    "                        feature_paths_for_frame[domain] = feature_path\n",
    "                    \n",
    "                    if feature_paths_exist:\n",
    "                        self.features.append(feature_paths_for_frame)\n",
    "                        self.labels.append(1 if label == 'fake' else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_paths = self.features[idx]\n",
    "        \n",
    "        # Load and concatenate features from all specified domains\n",
    "        loaded_features = [np.load(feature_paths[domain]) for domain in self.domains]\n",
    "        combined_features = np.concatenate(loaded_features).astype(np.float32)\n",
    "        \n",
    "        label = np.float32(self.labels[idx])\n",
    "        \n",
    "        return torch.from_numpy(combined_features), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f815795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters directly (no argparse)\n",
    "default_epochs = 10\n",
    "default_batch_size = 128\n",
    "default_lr = 1e-4\n",
    "\n",
    "# Model configurations for different domains\n",
    "configs = {\n",
    "    'Spatial': {\n",
    "        'domains': ['spatial'],\n",
    "        'epochs': 15,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 2e-4,\n",
    "        'hidden_dim1': 1024,\n",
    "        'hidden_dim2': 512,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'Frequency': {\n",
    "        'domains': ['frequency'],\n",
    "        'epochs': 20,\n",
    "        'batch_size': 256,\n",
    "        'learning_rate': 5e-4,\n",
    "        'hidden_dim1': 128,\n",
    "        'hidden_dim2': 64,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'Semantic': {\n",
    "        'domains': ['semantic'],\n",
    "        'epochs': 12,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-4,\n",
    "        'hidden_dim1': 512,\n",
    "        'hidden_dim2': 256,\n",
    "        'dropout': 0.4\n",
    "    },\n",
    "    'Fused (All)': {\n",
    "        'domains': ['spatial', 'frequency', 'semantic'],\n",
    "        'epochs': 10,\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 1e-4,\n",
    "        'hidden_dim1': 512,\n",
    "        'hidden_dim2': 256,\n",
    "        'dropout': 0.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421bdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(domains, epochs, batch_size, learning_rate, hidden_dim1=512, hidden_dim2=256, dropout=0.5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model for a given set of feature domains.\n",
    "    Windows/Jupyter DataLoader is set to num_workers=0 and disables\n",
    "    pin_memory and persistent_workers on CPU to prevent hangs.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Pipeline for Domain(s): {', '.join(domains)} ---\")\n",
    "    print(f\"Hyperparameters: epochs={epochs}, batch_size={batch_size}, lr={learning_rate}\")\n",
    "    print(f\"Model architecture: hidden_dims=({hidden_dim1}, {hidden_dim2}), dropout={dropout}\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = FeatureDataset(domains=domains, split='train')\n",
    "    val_dataset = FeatureDataset(domains=domains, split='val')\n",
    "\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"\\nERROR: Dataset is empty.\")\n",
    "        print(\"Please ensure feature extraction was successful and that the 'extracted_features' directory is not empty.\")\n",
    "        return None\n",
    "\n",
    "    # Windows/Jupyter-safe DataLoader settings\n",
    "    is_windows = platform.system() == 'Windows'\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    num_workers = 0 if is_windows else 4\n",
    "    pin_memory = use_cuda\n",
    "    persistent_workers = num_workers > 0\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers\n",
    "    )\n",
    "\n",
    "    # Define model, loss, optimizer\n",
    "    input_dim = train_dataset[0][0].shape[0]\n",
    "    model = MLP(input_dim=input_dim, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, dropout=dropout)\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n",
    "            features, labels = features.to(device), labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\"):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten() >= 0.5\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    print(f\"Validation Metrics: Acc: {accuracy:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return {'Domain': ' + '.join(domains), 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Pipeline for Domain(s): spatial ---\n",
      "Hyperparameters: epochs=15, batch_size=64, lr=0.0002\n",
      "Model architecture: hidden_dims=(1024, 512), dropout=0.3\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 682.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 665.39it/s]\n",
      "Epoch 1/15 [Training]: 100%|██████████| 88/88 [00:05<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.4222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 25.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.3446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.3095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Training]: 100%|██████████| 88/88 [00:03<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Training]: 100%|██████████| 88/88 [00:05<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.2721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Training]: 100%|██████████| 88/88 [00:04<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Training]: 100%|██████████| 88/88 [00:05<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Training]: 100%|██████████| 88/88 [00:04<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 [Training]: 100%|██████████| 88/88 [00:07<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 [Training]: 100%|██████████| 88/88 [00:04<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 [Training]: 100%|██████████| 88/88 [00:05<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 [Validation]: 100%|██████████| 22/22 [00:00<00:00, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: Acc: 0.7305, Prec: 0.8665, Rec: 0.8224, F1: 0.8439\n",
      "\n",
      "--- Running Pipeline for Domain(s): frequency ---\n",
      "Hyperparameters: epochs=20, batch_size=256, lr=0.0005\n",
      "Model architecture: hidden_dims=(128, 64), dropout=0.1\n",
      "Loading train dataset with 280 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train features: 100%|██████████| 280/280 [00:00<00:00, 403.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset with 70 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val features: 100%|██████████| 70/70 [00:00<00:00, 499.09it/s]\n",
      "Epoch 1/20 [Training]:   9%|▉         | 2/22 [00:04<00:44,  2.24s/it]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, config in configs.items():\n",
    "    result = run_pipeline(\n",
    "        domains=config['domains'],\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        hidden_dim1=config['hidden_dim1'],\n",
    "        hidden_dim2=config['hidden_dim2'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# --- Print Final Comparison Table ---\n",
    "if results:\n",
    "    print(\"\\n\\n--- Final Performance Comparison ---\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45182c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb4cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc00a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc5782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
